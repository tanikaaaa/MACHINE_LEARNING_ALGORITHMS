{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0975f5ee",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import layers, Model, Input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8c6f14",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"img_align_celeba\"   \n",
    "OUTPUT_DIR = \"generate_face\"    \n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "IMG_SIZE = 64\n",
    "Z_DIM = 100\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b139ac",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Loading dataset...\")\n",
    "\n",
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=DATA_DIR,\n",
    "    label_mode=None,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2515c1c3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda x: (x / 127.5) - 1.0)\n",
    "dataset = dataset.prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e6c7fa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def build_discriminator(img_shape=(IMG_SIZE, IMG_SIZE, 3)):\n",
    "    inp = Input(shape=img_shape)\n",
    "\n",
    "    x = layers.Conv2D(64, 4, strides=2, padding=\"same\")(inp)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = layers.Conv2D(128, 4, strides=2, padding=\"same\")(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = layers.Conv2D(256, 4, strides=2, padding=\"same\")(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = layers.Conv2D(512, 4, strides=2, padding=\"same\")(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inp, out)\n",
    "    return model\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "discriminator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e081fd14",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def build_generator(z_dim=Z_DIM):\n",
    "    inp = Input(shape=(z_dim,))\n",
    "\n",
    "    x = layers.Dense(8 * 8 * 256, use_bias=False)(inp)\n",
    "    x = layers.Reshape((8, 8, 256))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(128, 4, strides=2, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(64, 4, strides=2, padding=\"same\", use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(3, 4, strides=2, padding=\"same\", activation=\"tanh\")(x)\n",
    "\n",
    "    model = Model(inp, x)\n",
    "    return model\n",
    "\n",
    "generator = build_generator()\n",
    "generator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0094be",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "disc_optimizer = tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5)\n",
    "gen_optimizer = tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705ff81a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(real_images):\n",
    "    batch_size = tf.shape(real_images)[0]\n",
    "    noise = tf.random.normal([batch_size, Z_DIM])\n",
    "\n",
    "    with tf.GradientTape() as disc_tape, tf.GradientTape() as gen_tape:\n",
    "        fake_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(real_images, training=True)\n",
    "        fake_output = discriminator(fake_images, training=True)\n",
    "\n",
    "        real_labels = tf.ones_like(real_output) * 0.9\n",
    "        fake_labels = tf.zeros_like(fake_output)\n",
    "\n",
    "        d_loss_real = cross_entropy(real_labels, real_output)\n",
    "        d_loss_fake = cross_entropy(fake_labels, fake_output)\n",
    "        disc_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "        gen_labels = tf.ones_like(fake_output)\n",
    "        gen_loss = cross_entropy(gen_labels, fake_output)\n",
    "\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "\n",
    "    disc_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    gen_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "\n",
    "    return disc_loss, gen_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e24eed3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def denormalize(img):\n",
    "    return (img + 1.0) / 2.0\n",
    "\n",
    "def generate_images(epoch, seed):\n",
    "    predictions = generator(seed, training=False)\n",
    "    predictions = denormalize(predictions)\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(predictions[i])\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    path = os.path.join(OUTPUT_DIR, f\"samples_epoch_{epoch:03d}.png\")\n",
    "    plt.savefig(path)\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved: {path}\")\n",
    "\n",
    "\n",
    "seed = tf.random.normal([16, Z_DIM])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2365b4d5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\n===== Epoch {epoch+1}/{epochs} =====\")\n",
    "        for step, real_images in enumerate(dataset):\n",
    "            d_loss, g_loss = train_step(real_images)\n",
    "\n",
    "            if step % 100 == 0:\n",
    "                print(f\"Step {step} | D loss: {d_loss.numpy():.4f} | G loss: {g_loss.numpy():.4f}\")\n",
    "\n",
    "        generate_images(epoch, seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439f1575",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Training DCGAN...\")\n",
    "    train(dataset, EPOCHS)\n",
    "    print(\"Training complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
